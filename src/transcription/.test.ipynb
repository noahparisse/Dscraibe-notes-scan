{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8292a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoise import denoise_audio\n",
    "from diarisation import diarization_wav2vec2\n",
    "from enregistrement import record_loop\n",
    "from normalize import normalize_volume\n",
    "from transcribe import transcribe_w2v2\n",
    "from vad import VAD\n",
    "\n",
    "from pathlib import Path\n",
    "from huggingface_hub import login\n",
    "from pyannote.audio import Model\n",
    "from pyannote.audio.pipelines import VoiceActivityDetection\n",
    "import torchaudio\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import noisereduce as nr\n",
    "import torch\n",
    "from transformers import AutoModelForCTC, Wav2Vec2Processor\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ctc = AutoModelForCTC.from_pretrained(\"bhuang/asr-wav2vec2-french\").to(device)\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"bhuang/asr-wav2vec2-french\")\n",
    "model_sample_rate = processor.feature_extractor.sampling_rate\n",
    "\n",
    "model_segm = Model.from_pretrained(\n",
    "\"pyannote/segmentation-3.0\")\n",
    "\n",
    "pipeline = VoiceActivityDetection(segmentation=model_segm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41593262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_loop(duration, bruit_reduction=True, samplerate=16000):\n",
    "    \"\"\"\n",
    "    Enregistre des segments audio cons√©cutifs et les sauvegarde dans un dossier temporaire.\n",
    "    L'enregistrement s'arr√™te manuellement avec Ctrl+C ou automatiquement apr√®s `duration` secondes.\n",
    "\n",
    "    Args:\n",
    "        duration (float): Dur√©e de chaque segment audio.\n",
    "        bruit_reduction (bool): Appliquer une r√©duction de bruit.\n",
    "        samplerate (int): Taux d'√©chantillonnage audio.\n",
    "    \"\"\"\n",
    "    os.makedirs(\"tests\", exist_ok=True)\n",
    "    log_path = os.path.join(\"tests\", \"audio_brut.json\")\n",
    "\n",
    "    # Supprimer le fichier JSON existant\n",
    "    if os.path.exists(log_path):\n",
    "        os.remove(log_path)\n",
    "\n",
    "    logs = []\n",
    "    k = 1\n",
    "\n",
    "    print(\"Parlez (Ctrl+C pour arr√™ter).\")\n",
    "\n",
    "    try:\n",
    "        with sd.InputStream(samplerate=samplerate, channels=1, dtype='float32') as stream:\n",
    "            while True:\n",
    "                start_time = datetime.now()\n",
    "                safe_time = start_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                filename = f\"record_chunk_{k}_{safe_time}.wav\"\n",
    "                filepath = os.path.join(\"tests\", filename)\n",
    "\n",
    "                frames = []\n",
    "                while (datetime.now() - start_time).total_seconds() < duration:\n",
    "                    block = stream.read(1024)[0]\n",
    "                    frames.append(block)\n",
    "\n",
    "                recording = np.concatenate(frames, axis=0).squeeze()\n",
    "\n",
    "                if bruit_reduction:\n",
    "                    recording = nr.reduce_noise(y=recording, sr=samplerate)\n",
    "\n",
    "                sf.write(filepath, recording, samplerate)\n",
    "                end_time = datetime.now()\n",
    "\n",
    "                entry = {\n",
    "                    \"start_time\": start_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                    \"end_time\": end_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                    \"filename\": filename\n",
    "                }\n",
    "                logs.append(entry)\n",
    "\n",
    "                # Sauvegarde du JSON apr√®s chaque segment\n",
    "                with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(logs, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "                k += 1\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nArr√™t demand√© par l'utilisateur (Ctrl+C).\")\n",
    "\n",
    "        # Sauvegarde du dernier segment partiel (si existant)\n",
    "        if 'frames' in locals() and len(frames) > 0:\n",
    "            recording = np.concatenate(frames, axis=0).squeeze()\n",
    "            if bruit_reduction:\n",
    "                recording = nr.reduce_noise(y=recording, sr=samplerate)\n",
    "            sf.write(filepath, recording, samplerate)\n",
    "            end_time = datetime.now()\n",
    "\n",
    "            entry = {\n",
    "                \"start_time\": start_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"end_time\": end_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"filename\": filename\n",
    "            }\n",
    "            logs.append(entry)\n",
    "\n",
    "            with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(logs, f, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e411a6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parlez (Ctrl+C pour arr√™ter).\n",
      "\n",
      "Arr√™t demand√© par l'utilisateur (Ctrl+C).\n"
     ]
    }
   ],
   "source": [
    "record_loop(duration=5, bruit_reduction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b1d5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VADe(audio_path, min_duration_on=2.0, min_duration_off=2.0):\n",
    "    \n",
    "\n",
    "    HYPER_PARAMETERS = {\n",
    "    # Si un segment de parole d√©tect√© dure moins de 3 secondes, il sera ignor√©.\n",
    "    \"min_duration_on\": min_duration_on,\n",
    "    # Si une pause est plus courte que 10 secondes, elle peut √™tre remplie ou fusionn√©e avec les segments voisins.\n",
    "    \"min_duration_off\": min_duration_off\n",
    "    }\n",
    "    pipeline.instantiate(HYPER_PARAMETERS)\n",
    "    vad = pipeline(audio_path)\n",
    "\n",
    "    log_path = os.path.join(\"tmp\", \"transcriptions_log.json\")\n",
    "\n",
    "    # Charger le JSON existant s'il existe\n",
    "    if os.path.exists(log_path):\n",
    "        with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                logs = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                logs = []\n",
    "    else:\n",
    "        logs = []\n",
    "        \n",
    "        \n",
    "        \n",
    "    #Time\n",
    "    filename_brut = audio_path.name\n",
    "\n",
    "    with open(\"tests/audio_brut.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    entry = next((item for item in data if item[\"filename\"] == filename_brut ), None)\n",
    "\n",
    "    if entry:\n",
    "        i=0\n",
    "    else:\n",
    "        print(\"Aucun enregistrement trouv√© pour ce fichier.\")\n",
    "    \n",
    "    \n",
    "    start_time = entry[\"start_time\"]\n",
    "\n",
    "    \n",
    "    waveform, sr = torchaudio.load(audio_path)\n",
    "    i=0\n",
    "    for segment, _, _ in vad.itertracks(yield_label=True):\n",
    "        print(segment)\n",
    "        i = i+1\n",
    "        \n",
    "        s = int(segment.start)\n",
    "        e = int(segment.end)\n",
    "        \n",
    "        start = int(segment.start * sr)\n",
    "        end = int(segment.end * sr)\n",
    "        \n",
    "        segment = waveform[:, start:end]\n",
    "        \n",
    "        segment_filename = f\"{os.path.splitext(os.path.basename(audio_path))[0]}_segment_{i}.wav\"\n",
    "        segment_path = os.path.join(\"tmp\", segment_filename)\n",
    "        \n",
    "        torchaudio.save(segment_path, segment, sr)\n",
    "        \n",
    "        \n",
    "        base_start_str = start_time\n",
    "        base_start = datetime.strptime(base_start_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "        absolute_start = base_start + timedelta(seconds=s)\n",
    "        absolute_end = base_start + timedelta(seconds=e)\n",
    "        \n",
    "        \n",
    "        entry = {\n",
    "            \"start_time\": absolute_start.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"end_time\": absolute_end.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"filename\": segment_filename\n",
    "        }\n",
    "        logs.append(entry)\n",
    "        \n",
    "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(logs, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "    # --- üîΩ AJOUT DU TRI PAR DATE APR√àS SAUVEGARDE ---\n",
    "    with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        logs = json.load(f)\n",
    "\n",
    "    logs.sort(key=lambda x: datetime.strptime(x[\"start_time\"], \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "\n",
    "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(logs, f, indent=4, ensure_ascii=False)\n",
    "    # ------------------------------------------------ #\n",
    "\n",
    "    \n",
    "    data = [entry for entry in data if entry.get(\"filename\") != filename_brut]\n",
    "    with open(\"tests/audio_brut.json\", \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    \n",
    "    os.remove(audio_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5542e0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 00:00:00.030 -->  00:00:04.131]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedlbakali/Desktop/DTY/detection-notes/.venv/lib/python3.12/site-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
      "  warnings.warn(\n",
      "/Users/mohammedlbakali/Desktop/DTY/detection-notes/.venv/lib/python3.12/site-packages/torchaudio/_backend/ffmpeg.py:247: UserWarning: torio.io._streaming_media_encoder.StreamingMediaEncoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  s = torchaudio.io.StreamWriter(uri, format=muxer, buffer_size=buffer_size)\n"
     ]
    }
   ],
   "source": [
    "folder = Path(\"tests\")\n",
    "\n",
    "for audio_path in folder.glob(\"*.wav\"): \n",
    "    VADe(audio_path, min_duration_on=1, min_duration_off=2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff2801f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transcribe_w2v2(audio_path):\n",
    "    \"\"\"\n",
    "    Transcrit un fichier audio en texte √† l‚Äôaide d‚Äôun mod√®le Whisper.\n",
    "\n",
    "    Cette fonction charge un mod√®le Whisper pr√©entra√Æn√© de la taille sp√©cifi√©e,\n",
    "    puis effectue la transcription du fichier audio fourni.  \n",
    "    Elle peut √©galement utiliser un prompt initial pour guider la transcription\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    log_path = os.path.join(\"tmp\", \"transcriptions_log.json\")\n",
    "\n",
    "    # Charger le JSON existant s'il existe\n",
    "    if os.path.exists(log_path):\n",
    "        with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                logs = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                logs = []\n",
    "    else:\n",
    "        logs = []\n",
    "        \n",
    "        \n",
    "        \n",
    "    #Time\n",
    "    filename_brut = audio_path.name\n",
    "\n",
    "    entry = next((item for item in logs if item[\"filename\"] == filename_brut ), None)\n",
    "\n",
    "    if entry and \"transcription\" in entry:\n",
    "        # La transcription existe d√©j√†\n",
    "        return print(f\"Transcription d√©j√† pr√©sente pour {filename_brut}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    wav_path = audio_path\n",
    "    waveform, sample_rate = torchaudio.load(wav_path)\n",
    "    waveform = waveform.squeeze(axis=0)  # mono\n",
    "\n",
    "    # resample\n",
    "    if sample_rate != model_sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(sample_rate, model_sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # normalize\n",
    "    input_dict = processor(waveform, sampling_rate=model_sample_rate, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        logits = model_ctc(input_dict.input_values.to(device)).logits\n",
    "\n",
    "    # decode\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    predicted_sentence = processor.batch_decode(predicted_ids)[0]\n",
    "\n",
    "    entry[\"transcription\"] = predicted_sentence\n",
    "\n",
    "    os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
    "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(logs, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf028fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"tmp\")\n",
    "\n",
    "for audio_path in folder.glob(\"*.wav\"): \n",
    "    transcribe_w2v2(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3427a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
